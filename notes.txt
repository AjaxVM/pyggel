Figure out how to check if we have any data for texcs (or color or whatnot)
Can we check if the vertex attrib is enabled or not?
No we cannot - will need specific shaders for each type of thing, or default all values to something meaningful

Can we check if there is an active texture to use? IE we might get tex coords but have no texture...
Will that just appear white, or how does gl do that.
Also, what does the param for a sampler uniform mean - just passing 0 atm...

get other types of nodes going (render, light)
figure out a good way to let nodes add details without having to have root node need to be able to do all functions
or just bite bullet and do it that way

Will need to make Mesh REQUIRE all fields in it's definition
Can maybe default params if they are missing? IE color: vec4(1), texcs: vec2(0)
Can calculate triangle normals if they are not passed (will need to figure out the normal/parallax maps)

Shaders created to handle Mesh definition X Light definition

Calculate most effictive lights per mesh as:
    Light Intensity / Distance from Mesh
On tie (perhaps with threshold) elect to use closest light
This is simple alternative to deferred lighting perhaps?


Make sure to flag dependencies for our lib so we can add it to pip and have it work properly

Try again to use non-indexed writes and see how much faster it is
Add function to unwrap a mesh so that indexes are linear (0,1,2...N) and duplicate verts as necessary to allow this
Make normal calculation function take vertices/indices as arguments (indices being optional)

Can we simply specify stride of VBO data and unpack in shader maybe?

Check if setting the data format (stride/offset, etc.) at build time is sufficient or causes issues...
    It is waaaay faster if it is not something that has to be updated all the time

Consider using Pyrr for math
    Seems to be a no go, timeit shows our Vec3 being considerably faster than Pyrr's (possibly due to not putting everything into numpy?)
    for instantiation and dot product against self

    PyGLM, on the other hand, appears to run considerably faster - so might be worth converting to use it
    Or maybe, make it an optional enhancement where things use it if possible, but fallback to pure python implementation?
    There is the question about whether we can coerce glm types as args to OpenGL though...
        https://github.com/Zuzu-Typ/PyGLM/issues/1
    It would be cool to use the built in perspective and such matrices instead of building them...

    Interestingly - PyGLM converting vector was actualyl slower - might need to tweak interface to be more glm friendly?
    A task for another day though

Maybe define render passes that have attributes like, whether they affect transparent/not, whether they are lit, etc.
And, they have a shader attached, instead of passing a shader around everywhere

We need a lot of optimizations about pre_render, shader values, etc.

Implement simple HDR with exposure mapping: https://learnopengl.com/Advanced-Lighting/HDR

Render pipeline (forward):
    # use a single shader that can handle normal map/etc. to combine shiz
    Update nodes
    collect render nodes
    split render nodes into opaque/transparent
    order transparent back to front
    order opaque front to back
    collect lights
        Possibly figure out the N most impactful lights to each object (for forward rendering)
    render opaque objects
        bind only the N lights that impact the most + ambient/directional light(s?)
    render transparent objects
        do we need lighting on these or pass for now?

Figure out how to define/store/render materials

Look into using Uniform buffers for lights

Look at subsurface scattering: https://machinesdontcare.wordpress.com/2008/10/29/subsurface-scatter-shader/

Parse model into opaque and transparent bits (using color only, not texture!)
Offset transparent parts to 0 (and remember offset) - subtract by average in each direction
Create a function to get a render node from a mesh - and have it build one and child transform nodes (for offset) with child render node (for transparent part)

TODO: maybe make intensity for lights be calculated in engine and just send color through - so we have fewer calculations to do in gpu?
Maybe we don't care but I imagine those won't change frequently (but then again, consider a fire which will)

Remove the stupid "dirty" stuff - instead allow objects to register callbacks when they are changed

Think about caching node screen positions (others useful at all?) so we can do sorting/culling efficiently
    Inherit position from parent unless we are a TransformNode then calculate our own
    Actually - to do that we need to get LightNode utilizing the transform for position
    Which... makes it so it makes sense to cache our local position
    We should really define somewhere what means what, i.e. generally right now (might be exceptions):
        local position refers to where we want to be in the world - this is represented by the transform matrix
        view position is where in the world our view is position at - this is represented bt the view matrix (camera pos)
        world position is where in the world an object is based on local and offset by view - represented by scene matrix

Create extrapolation function to take indexed set of verts/texcs/etc.
    and map them into 3 verts -> face rather than reusing so normal mapping works better

How to handle reparenting with the root node reference and flat_list with children?
